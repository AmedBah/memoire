{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture 3: RAG-Agentique (Agent Augment√© par Outils)\n",
    "\n",
    "Cette architecture repr√©sente l'approche la plus sophistiqu√©e, combinant RAG avec des capacit√©s agentiques selon le paradigme ReAct (Reasoning + Acting).\n",
    "\n",
    "## Caract√©ristiques principales:\n",
    "- **Framework**: LangChain + LangGraph pour orchestration\n",
    "- **Paradigme**: ReAct (Thought-Action-Observation)\n",
    "- **Outils**: 4 outils m√©tier (RAG Retriever, Operator Info, Entity Extractor, Conversation Memory)\n",
    "- **Capacit√©s**: Raisonnement multi-√©tapes, planification, adaptation contextuelle\n",
    "- **Base**: Tout ce qui √©tait dans Architecture 2 + couche agentique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AmedBah/memoire/blob/main/notebooks/architecture_3/03_architecture_3_rag_agentique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab-setup"
   },
   "source": [
    "## üöÄ Configuration pour Google Colab\n",
    "\n",
    "**Note**: Cette section est sp√©cifique √† Google Colab. Si vous ex√©cutez ce notebook localement, vous pouvez ignorer ces cellules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "runtime-check"
   },
   "outputs": [],
   "source": [
    "# V√©rifier le type de runtime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# D√©tecter si on est sur Colab\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"‚úì Ex√©cution sur Google Colab\")\n",
    "    \n",
    "    # V√©rifier le type de GPU\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"‚úì GPU d√©tect√©: {gpu_name}\")\n",
    "        print(f\"‚úì M√©moire GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        \n",
    "        # Recommandations selon le GPU\n",
    "        if 'T4' in gpu_name:\n",
    "            print(\"\\n‚ö†Ô∏è  GPU T4 d√©tect√© (16 GB): Convient pour ce notebook mais les temps d'entra√Ænement seront plus longs\")\n",
    "        elif 'V100' in gpu_name or 'A100' in gpu_name:\n",
    "            print(f\"\\n‚úì {gpu_name}: Parfait pour ce notebook!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå ATTENTION: Aucun GPU d√©tect√©!\")\n",
    "        print(\"   Pour activer le GPU: Runtime > Change runtime type > GPU\")\n",
    "        print(\"   Pour Colab Pro: Choisir 'High-RAM' ou 'Premium GPU'\")\n",
    "else:\n",
    "    print(\"‚úì Ex√©cution locale\")\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úì GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Aucun GPU d√©tect√© - l'entra√Ænement sera tr√®s lent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Monter Google Drive (uniquement sur Colab)\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # D√©finir le chemin vers les donn√©es\n",
    "    # OPTION 1: Donn√©es dans Google Drive\n",
    "    # DATA_DIR = '/content/drive/MyDrive/memoire/data'\n",
    "    \n",
    "    # OPTION 2: Cloner le repo et utiliser les donn√©es locales\n",
    "    print(\"\\nüì• Clonage du repository...\")\n",
    "    !git clone https://github.com/AmedBah/memoire.git /content/memoire\n",
    "    DATA_DIR = '/content/memoire/data'\n",
    "    \n",
    "    print(f\"\\n‚úì R√©pertoire de donn√©es: {DATA_DIR}\")\n",
    "    \n",
    "    # V√©rifier que les donn√©es sont pr√©sentes\n",
    "    if os.path.exists(DATA_DIR):\n",
    "        print(\"‚úì Donn√©es trouv√©es!\")\n",
    "        !ls -lh {DATA_DIR}\n",
    "    else:\n",
    "        print(f\"‚ùå ERREUR: R√©pertoire {DATA_DIR} non trouv√©!\")\n",
    "        print(\"   Veuillez soit:\")\n",
    "        print(\"   1. Copier le dossier 'data' dans votre Google Drive\")\n",
    "        print(\"   2. Ou le repository sera clon√© automatiquement\")\n",
    "else:\n",
    "    # Ex√©cution locale\n",
    "    DATA_DIR = '../../data'\n",
    "    print(f\"‚úì R√©pertoire de donn√©es local: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-path-helper"
   },
   "outputs": [],
   "source": [
    "# Fonction helper pour obtenir les chemins de donn√©es\n",
    "def get_data_path(relative_path):\n",
    "    \"\"\"Obtenir le chemin absolu d'un fichier de donn√©es\"\"\"\n",
    "    return os.path.join(DATA_DIR, relative_path)\n",
    "\n",
    "# Exemples de chemins\n",
    "print(\"Chemins de donn√©es configur√©s:\")\n",
    "print(f\"  Conversations: {get_data_path('conversations/conversation_1000_finetune.jsonl')}\")\n",
    "print(f\"  FAQs: {get_data_path('faqs/faq_easytransfert.json')}\")\n",
    "print(f\"  Op√©rateurs: {get_data_path('operators/operators_info.json')}\")\n",
    "print(f\"  Proc√©dures: {get_data_path('procedures/procedures_resolution.json')}\")\n",
    "print(f\"  Expressions: {get_data_path('expressions/expressions_ivoiriennes.json')}\")\n",
    "print(f\"  Documents: {get_data_path('documents/doc.txt.txt')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances\n",
    "!pip install -q langchain langchain-community langgraph chromadb sentence-transformers transformers torch\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "print(f\"GPU disponible: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialisation ChromaDB et Embedding (identique Architecture 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©utiliser la base ChromaDB de l'Architecture 2\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chromadb_easytransfert\")\n",
    "embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"easytransfert_knowledge_base\",\n",
    "    metadata={\"description\": \"Base de connaissances EasyTransfert pour RAG\"}\n",
    ")\n",
    "\n",
    "print(f\"Collection charg√©e: {collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Outil 1: RAG Retriever\n",
    "\n",
    "Encapsulation de la recherche vectorielle comme outil invocable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "\n",
    "class RAGRetrieverTool(BaseTool):\n",
    "    name: str = \"rag_retriever\"\n",
    "    description: str = \"\"\"Recherche d'informations dans la base de connaissances EasyTransfert.\n",
    "    Utilise ce tool pour trouver des informations sur:\n",
    "    - FAQ et questions fr√©quentes\n",
    "    - Proc√©dures de r√©solution de probl√®mes\n",
    "    - Documentation des op√©rateurs\n",
    "    - Historique de conversations\n",
    "    \n",
    "    Entr√©e: Une question ou requ√™te en fran√ßais\n",
    "    Sortie: Liste de documents pertinents avec m√©tadonn√©es\n",
    "    \"\"\"\n",
    "    \n",
    "    def _run(self, query: str, top_k: int = 3) -> str:\n",
    "        \"\"\"Recherche synchrone\"\"\"\n",
    "        query_embedding = embedding_model.encode([query])[0]\n",
    "        \n",
    "        results = collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=top_k,\n",
    "        )\n",
    "        \n",
    "        # Formater les r√©sultats\n",
    "        formatted_results = []\n",
    "        for i in range(len(results['documents'][0])):\n",
    "            distance = results['distances'][0][i]\n",
    "            similarity = 1 - distance\n",
    "            \n",
    "            formatted_results.append({\n",
    "                \"content\": results['documents'][0][i],\n",
    "                \"category\": results['metadatas'][0][i].get('category', 'unknown'),\n",
    "                \"source\": results['metadatas'][0][i].get('source', 'interne'),\n",
    "                \"score\": round(similarity, 3)\n",
    "            })\n",
    "        \n",
    "        return json.dumps(formatted_results, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Recherche asynchrone\"\"\"\n",
    "        return self._run(query)\n",
    "\n",
    "rag_tool = RAGRetrieverTool()\n",
    "print(\"Outil RAG Retriever cr√©√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Outil 2: Operator Info\n",
    "\n",
    "Consultation d'informations structur√©es sur les op√©rateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperatorInfoTool(BaseTool):\n",
    "    name: str = \"operator_info\"\n",
    "    description: str = \"\"\"Consulte les informations structur√©es sur les op√©rateurs mobiles.\n",
    "    Fournit des donn√©es techniques:\n",
    "    - Formats d'identifiants de transaction\n",
    "    - Limites min/max de transfert\n",
    "    - Frais de transaction\n",
    "    - Pr√©fixes de num√©ros de t√©l√©phone\n",
    "    - Compatibilit√©s inter-op√©rateurs\n",
    "    \n",
    "    Entr√©e: Nom de l'op√©rateur (MTN, Orange, Moov, Wave, Tr√©sor Money) ou 'tous'\n",
    "    Sortie: Informations d√©taill√©es sur l'op√©rateur\n",
    "    \"\"\"\n",
    "    \n",
    "    # Base de donn√©es fictive des op√©rateurs\n",
    "    operators_db = {\n",
    "        \"MTN\": {\n",
    "            \"nom_complet\": \"MTN Mobile Money\",\n",
    "            \"format_id\": \"Chiffres uniquement (g√©n√©ralement 10 chiffres)\",\n",
    "            \"exemple_id\": \"1234567890\",\n",
    "            \"limite_min\": \"100 FCFA\",\n",
    "            \"limite_max\": \"2 000 000 FCFA\",\n",
    "            \"frais\": \"1-2% (min 25 FCFA, max 500 FCFA)\",\n",
    "            \"prefixes\": [\"05\", \"06\", \"07\"],\n",
    "            \"compatible_avec\": [\"Orange\", \"Moov\", \"Wave\", \"Tr√©sor Money\"]\n",
    "        },\n",
    "        \"Orange\": {\n",
    "            \"nom_complet\": \"Orange Money\",\n",
    "            \"format_id\": \"MP suivi de 10 chiffres (envoi)\",\n",
    "            \"exemple_id\": \"MP1234567890\",\n",
    "            \"limite_min\": \"100 FCFA\",\n",
    "            \"limite_max\": \"1 500 000 FCFA\",\n",
    "            \"frais\": \"1-2% (min 25 FCFA, max 500 FCFA)\",\n",
    "            \"prefixes\": [\"07\", \"08\", \"09\"],\n",
    "            \"compatible_avec\": [\"MTN\", \"Moov\", \"Wave\", \"Tr√©sor Money\"]\n",
    "        },\n",
    "        \"Moov\": {\n",
    "            \"nom_complet\": \"Moov Money\",\n",
    "            \"format_id\": \"MRCH* ou CF* + alphanum√©riques (envoi)\",\n",
    "            \"exemple_id\": \"MRCH123456 ou CF789012\",\n",
    "            \"limite_min\": \"100 FCFA\",\n",
    "            \"limite_max\": \"1 000 000 FCFA\",\n",
    "            \"frais\": \"1-2% (min 25 FCFA, max 500 FCFA)\",\n",
    "            \"prefixes\": [\"01\", \"02\"],\n",
    "            \"compatible_avec\": [\"MTN\", \"Orange\", \"Wave\", \"Tr√©sor Money\"]\n",
    "        },\n",
    "        \"Wave\": {\n",
    "            \"nom_complet\": \"Wave\",\n",
    "            \"format_id\": \"Format variable, souvent T + chiffres\",\n",
    "            \"exemple_id\": \"T123456789\",\n",
    "            \"limite_min\": \"100 FCFA\",\n",
    "            \"limite_max\": \"5 000 000 FCFA\",\n",
    "            \"frais\": \"1% (min 25 FCFA, max 500 FCFA)\",\n",
    "            \"prefixes\": [\"05\", \"07\"],\n",
    "            \"compatible_avec\": [\"MTN\", \"Orange\", \"Moov\", \"Tr√©sor Money\"]\n",
    "        },\n",
    "        \"Tr√©sor Money\": {\n",
    "            \"nom_complet\": \"Tr√©sor Money (Tr√©mo)\",\n",
    "            \"format_id\": \"Format variable selon transaction\",\n",
    "            \"exemple_id\": \"Variable\",\n",
    "            \"limite_min\": \"100 FCFA\",\n",
    "            \"limite_max\": \"1 000 000 FCFA\",\n",
    "            \"frais\": \"1-2% (min 25 FCFA, max 500 FCFA)\",\n",
    "            \"prefixes\": [\"05\"],\n",
    "            \"compatible_avec\": [\"MTN\", \"Orange\", \"Moov\", \"Wave\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def _run(self, operator_name: str) -> str:\n",
    "        \"\"\"Recherche synchrone\"\"\"\n",
    "        operator_name = operator_name.strip().title()\n",
    "        \n",
    "        if operator_name.lower() == \"tous\" or operator_name.lower() == \"all\":\n",
    "            return json.dumps(self.operators_db, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # Chercher l'op√©rateur\n",
    "        for key in self.operators_db:\n",
    "            if operator_name in key or key in operator_name:\n",
    "                return json.dumps({key: self.operators_db[key]}, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        return json.dumps({\"error\": f\"Op√©rateur '{operator_name}' non trouv√©. Op√©rateurs disponibles: MTN, Orange, Moov, Wave, Tr√©sor Money\"}, ensure_ascii=False)\n",
    "    \n",
    "    async def _arun(self, operator_name: str) -> str:\n",
    "        return self._run(operator_name)\n",
    "\n",
    "operator_tool = OperatorInfoTool()\n",
    "print(\"Outil Operator Info cr√©√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Outil 3: Entity Extractor\n",
    "\n",
    "Extraction d'entit√©s nomm√©es via regex et r√®gles m√©tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityExtractorTool(BaseTool):\n",
    "    name: str = \"entity_extractor\"\n",
    "    description: str = \"\"\"Extrait des entit√©s structur√©es d'un texte utilisateur.\n",
    "    Identifie:\n",
    "    - Identifiants EasyTransfert (EFB.*)\n",
    "    - Identifiants op√©rateurs (MTN, Orange MP*, Moov MRCH*/CF*, Wave T*)\n",
    "    - Num√©ros de t√©l√©phone\n",
    "    - Montants en FCFA\n",
    "    - Noms d'op√©rateurs mentionn√©s\n",
    "    \n",
    "    Entr√©e: Texte contenant potentiellement des entit√©s\n",
    "    Sortie: Dictionnaire des entit√©s extraites par cat√©gorie\n",
    "    \"\"\"\n",
    "    \n",
    "    patterns = {\n",
    "        \"easytransfert_id\": r\"EFB\\.[A-Z0-9]+\",\n",
    "        \"mtn_id\": r\"\\b\\d{10,}\\b\",\n",
    "        \"orange_id\": r\"MP\\d{10}\",\n",
    "        \"moov_id\": r\"(MRCH|CF)[A-Z0-9]+\",\n",
    "        \"wave_id\": r\"T\\d+\",\n",
    "        \"phone\": r\"(\\+225)?\\s?[0-9]{8,10}\",\n",
    "        \"amount\": r\"\\d+\\s*(FCFA|CFA|francs?|F)?\",\n",
    "        \"operators\": r\"(MTN|Orange|Moov|Wave|Tr√©sor\\s?Money|Tremo)\"\n",
    "    }\n",
    "    \n",
    "    def _run(self, text: str) -> str:\n",
    "        \"\"\"Extraction synchrone\"\"\"\n",
    "        extracted = {}\n",
    "        \n",
    "        for entity_type, pattern in self.patterns.items():\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                extracted[entity_type] = list(set(matches))  # D√©dupliquation\n",
    "        \n",
    "        if not extracted:\n",
    "            return json.dumps({\"message\": \"Aucune entit√© d√©tect√©e\"}, ensure_ascii=False)\n",
    "        \n",
    "        return json.dumps(extracted, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    async def _arun(self, text: str) -> str:\n",
    "        return self._run(text)\n",
    "\n",
    "entity_tool = EntityExtractorTool()\n",
    "print(\"Outil Entity Extractor cr√©√©\")\n",
    "\n",
    "# Test\n",
    "test_text = \"Mon transfert EFB.ABC123 de 50000 FCFA vers MTN n'est pas arriv√©. Mon num√©ro est 0758123456\"\n",
    "print(f\"\\nTest extraction: {test_text}\")\n",
    "print(entity_tool._run(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outil 4: Conversation Memory\n",
    "\n",
    "Gestion de l'historique conversationnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationMemoryTool(BaseTool):\n",
    "    name: str = \"conversation_memory\"\n",
    "    description: str = \"\"\"G√®re l'historique de la conversation avec l'utilisateur.\n",
    "    Permet de:\n",
    "    - R√©cup√©rer le contexte de la conversation actuelle\n",
    "    - Rechercher des probl√®mes similaires pass√©s\n",
    "    - √âviter de redemander des informations d√©j√† fournies\n",
    "    \n",
    "    Entr√©e: 'get_history' pour r√©cup√©rer l'historique ou une requ√™te pour chercher\n",
    "    Sortie: Historique ou r√©sultats de recherche\n",
    "    \"\"\"\n",
    "    \n",
    "    # Stockage en m√©moire (dans une vraie impl√©mentation, utiliser une base de donn√©es)\n",
    "    memory_store: Dict[str, List[Dict]] = {}\n",
    "    \n",
    "    def _run(self, query: str, user_id: str = \"default\") -> str:\n",
    "        \"\"\"Op√©ration synchrone\"\"\"\n",
    "        \n",
    "        if user_id not in self.memory_store:\n",
    "            self.memory_store[user_id] = []\n",
    "        \n",
    "        if query.lower() == \"get_history\":\n",
    "            return json.dumps({\n",
    "                \"history\": self.memory_store[user_id],\n",
    "                \"count\": len(self.memory_store[user_id])\n",
    "            }, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # Chercher dans l'historique\n",
    "        relevant = []\n",
    "        for entry in self.memory_store[user_id]:\n",
    "            if any(word.lower() in entry.get(\"content\", \"\").lower() for word in query.split()):\n",
    "                relevant.append(entry)\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"relevant_entries\": relevant,\n",
    "            \"count\": len(relevant)\n",
    "        }, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    async def _arun(self, query: str, user_id: str = \"default\") -> str:\n",
    "        return self._run(query, user_id)\n",
    "    \n",
    "    def add_to_memory(self, user_id: str, role: str, content: str):\n",
    "        \"\"\"Ajoute un message √† la m√©moire\"\"\"\n",
    "        if user_id not in self.memory_store:\n",
    "            self.memory_store[user_id] = []\n",
    "        \n",
    "        self.memory_store[user_id].append({\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "memory_tool = ConversationMemoryTool()\n",
    "print(\"Outil Conversation Memory cr√©√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Configuration du LLM et de l'Agent ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le mod√®le LLM\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "# Cr√©er le pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "print(\"LLM charg√© avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prompt ReAct pour l'Agent\n",
    "\n",
    "Template structurant le cycle Thought-Action-Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_prompt_template = \"\"\"Tu es un agent intelligent du service client EasyTransfert.\n",
    "Tu as acc√®s aux outils suivants pour aider les utilisateurs:\n",
    "\n",
    "{tools}\n",
    "\n",
    "PARADIGME ReAct - Cycle Pens√©e-Action-Observation:\n",
    "\n",
    "Pour chaque requ√™te utilisateur, suis ce processus it√©ratif:\n",
    "\n",
    "1. Thought (Pens√©e): Analyse la situation et planifie la prochaine √©tape\n",
    "2. Action: Choisis un outil et sp√©cifie l'entr√©e\n",
    "3. Observation: Examine le r√©sultat de l'action\n",
    "4. R√©p√®te jusqu'√† avoir assez d'informations pour r√©pondre\n",
    "\n",
    "FORMAT DE R√âPONSE:\n",
    "\n",
    "Thought: [ton raisonnement sur ce qu'il faut faire]\n",
    "Action: [nom de l'outil √† utiliser]\n",
    "Action Input: [entr√©e pour l'outil]\n",
    "Observation: [r√©sultat retourn√© par l'outil]\n",
    "... (r√©p√©ter Thought/Action/Observation autant que n√©cessaire)\n",
    "Thought: J'ai maintenant assez d'informations pour r√©pondre\n",
    "Final Answer: [ta r√©ponse finale √† l'utilisateur]\n",
    "\n",
    "R√àGLES IMPORTANTES:\n",
    "- Utilise les outils de mani√®re strat√©gique\n",
    "- Pour les probl√®mes de transaction, extrais d'abord les entit√©s puis cherche dans la base\n",
    "- Cite toujours tes sources quand tu utilises rag_retriever\n",
    "- V√©rifie la m√©moire pour √©viter de redemander des informations\n",
    "- Ton chaleureux avec √©mojis ü§óüòä\n",
    "- En cas de doute, r√©f√©rence au service client: 2522018730\n",
    "\n",
    "Commence maintenant!\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "react_prompt = PromptTemplate(\n",
    "    template=react_prompt_template,\n",
    "    input_variables=[\"tools\", \"input\", \"agent_scratchpad\"]\n",
    ")\n",
    "\n",
    "print(\"Prompt ReAct d√©fini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cr√©ation de l'Agent ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des outils disponibles\n",
    "tools = [\n",
    "    rag_tool,\n",
    "    operator_tool,\n",
    "    entity_tool,\n",
    "    memory_tool\n",
    "]\n",
    "\n",
    "# Cr√©er l'agent ReAct\n",
    "agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=react_prompt\n",
    ")\n",
    "\n",
    "# Cr√©er l'executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    max_iterations=5,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "print(\"Agent ReAct cr√©√© et pr√™t!\")\n",
    "print(f\"Nombre d'outils disponibles: {len(tools)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Fonction de Chat Agentique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_chat(query: str, user_id: str = \"default\") -> Dict:\n",
    "    \"\"\"\n",
    "    Chat avec l'agent ReAct\n",
    "    \n",
    "    Args:\n",
    "        query: Question de l'utilisateur\n",
    "        user_id: Identifiant utilisateur pour la m√©moire\n",
    "    \n",
    "    Returns:\n",
    "        Dict avec r√©ponse, outils utilis√©s et m√©triques\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Ajouter √† la m√©moire\n",
    "    memory_tool.add_to_memory(user_id, \"user\", query)\n",
    "    \n",
    "    # Ex√©cuter l'agent\n",
    "    try:\n",
    "        result = agent_executor.invoke({\"input\": query})\n",
    "        response = result.get(\"output\", \"Je n'ai pas pu g√©n√©rer une r√©ponse. Contactez le 2522018730 ü§ó\")\n",
    "        \n",
    "        # Ajouter la r√©ponse √† la m√©moire\n",
    "        memory_tool.add_to_memory(user_id, \"assistant\", response)\n",
    "        \n",
    "    except Exception as e:\n",
    "        response = f\"Une erreur s'est produite: {str(e)}. Contactez le service client au 2522018730 ü§ó\"\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"execution_time_ms\": total_time * 1000,\n",
    "        \"user_id\": user_id\n",
    "    }\n",
    "\n",
    "print(\"Fonction de chat agentique d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Tests de l'Agent ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests progressifs\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"name\": \"Question FAQ simple\",\n",
    "        \"query\": \"Quels sont les op√©rateurs support√©s par EasyTransfert ?\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Extraction d'entit√©s + recherche op√©rateur\",\n",
    "        \"query\": \"Quel est le format d'identifiant pour Orange Money ?\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Probl√®me complexe avec extraction\",\n",
    "        \"query\": \"Mon transfert EFB.ABC123 de 50000 FCFA vers MTN n'est pas arriv√©\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Multi-√©tapes avec m√©moire\",\n",
    "        \"query\": \"Je veux v√©rifier les limites de transfert pour l'op√©rateur que j'ai mentionn√©\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TESTS DE L'AGENT ReAct\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, scenario in enumerate(test_scenarios, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Test {i}: {scenario['name']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Question: {scenario['query']}\\n\")\n",
    "    \n",
    "    result = agentic_chat(scenario['query'])\n",
    "    \n",
    "    print(f\"\\nR√©ponse: {result['response']}\")\n",
    "    print(f\"\\nTemps d'ex√©cution: {result['execution_time_ms']:.0f}ms\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Analyse des Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# M√©triques de performance\n",
    "execution_times = []\n",
    "\n",
    "test_queries = [\n",
    "    \"Comment faire un transfert ?\",\n",
    "    \"Quels sont les frais ?\",\n",
    "    \"Mon argent n'est pas arriv√©\",\n",
    "    \"Format identifiant Wave ?\",\n",
    "    \"Limite de transfert MTN ?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    result = agentic_chat(query)\n",
    "    execution_times.append(result['execution_time_ms'])\n",
    "\n",
    "print(\"\\nM√âTRIQUES DE PERFORMANCE - ARCHITECTURE 3 (RAG-Agentique)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Temps d'ex√©cution:\")\n",
    "print(f\"  - Moyenne: {np.mean(execution_times):.0f}ms\")\n",
    "print(f\"  - M√©diane: {np.median(execution_times):.0f}ms\")\n",
    "print(f\"  - Min/Max: {np.min(execution_times):.0f}ms / {np.max(execution_times):.0f}ms\")\n",
    "print(f\"  - √âcart-type: {np.std(execution_times):.0f}ms\")\n",
    "print(f\"\\nOutils disponibles: {len(tools)}\")\n",
    "print(f\"Capacit√©s agentiques: Raisonnement multi-√©tapes, utilisation d'outils, m√©moire contextuelle\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Comparaison des 3 Architectures\n",
    "\n",
    "### Architecture 1 (Baseline - Fine-tuning):\n",
    "- ‚ö° **Latence**: ~2-3s\n",
    "- üíæ **M√©moire**: Faible (~50 MB adaptateurs LoRA)\n",
    "- üéØ **Complexit√©**: Tr√®s simple\n",
    "- ‚ùå **Hallucinations**: Risque √©lev√©\n",
    "- ‚ùå **Actualisation**: N√©cessite r√©entra√Ænement\n",
    "- ‚ùå **Tra√ßabilit√©**: Aucune\n",
    "\n",
    "### Architecture 2 (RAG Standard):\n",
    "- ‚ö° **Latence**: ~2-3.5s (r√©cup√©ration + g√©n√©ration)\n",
    "- üíæ **M√©moire**: Moyenne (ChromaDB + LLM)\n",
    "- üéØ **Complexit√©**: Mod√©r√©e\n",
    "- ‚úÖ **Hallucinations**: Fortement r√©duit\n",
    "- ‚úÖ **Actualisation**: Ajout de documents sans r√©entra√Ænement\n",
    "- ‚úÖ **Tra√ßabilit√©**: Citations des sources\n",
    "- ‚ùå **Raisonnement**: Limit√© aux requ√™tes simples\n",
    "\n",
    "### Architecture 3 (RAG-Agentique):\n",
    "- ‚ö° **Latence**: ~3-5s (cycle ReAct it√©ratif)\n",
    "- üíæ **M√©moire**: √âlev√©e (ChromaDB + LLM + outils)\n",
    "- üéØ **Complexit√©**: √âlev√©e\n",
    "- ‚úÖ **Hallucinations**: Minimis√© (validation par outils)\n",
    "- ‚úÖ **Actualisation**: Mise √† jour des outils et base\n",
    "- ‚úÖ **Tra√ßabilit√©**: Compl√®te (cycle ReAct visible)\n",
    "- ‚úÖ **Raisonnement**: Multi-√©tapes et planification\n",
    "- ‚úÖ **Outils**: Acc√®s bases de donn√©es, APIs externes\n",
    "- ‚úÖ **Adaptation**: Contextuelle et √©motionnelle\n",
    "\n",
    "### Conclusion:\n",
    "L'Architecture 3 repr√©sente la solution la plus compl√®te pour un service client automatis√© intelligent. Elle combine:\n",
    "- La fiabilit√© du RAG (Architecture 2)\n",
    "- L'autonomie d√©cisionnelle des agents\n",
    "- L'acc√®s √† des outils m√©tier sp√©cialis√©s\n",
    "- La capacit√© de raisonnement multi-√©tapes\n",
    "\n",
    "Le surco√ªt en latence (~1-2s) est justifi√© par la qualit√© et la pertinence accrues des r√©ponses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}