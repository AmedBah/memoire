# Notebooks - Architectures Conversationnelles EasyTransfert

## üìö Vue d'ensemble

Ce dossier contient deux notebooks Jupyter ex√©cutables sur Google Colab, impl√©mentant et comparant deux approches d'intelligence artificielle conversationnelle pour l'automatisation du service client d'EasyTransfert.

## üéØ Notebooks disponibles

### 1. Architecture 1 : Agent LLM (Llama 3.2 + LoRA)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AmedBah/memoire/blob/main/nouvelle_approche/notebooks/Architecture_1_Agent_LLM.ipynb)

**Fichier**: `Architecture_1_Agent_LLM.ipynb`

**Approche**: Agent conversationnel end-to-end bas√© sur un Large Language Model

**Caract√©ristiques**:
- Mod√®le: Llama 3.2 3B Instruct
- Technique: LoRA (Low-Rank Adaptation) - r=16, alpha=32
- Framework: Unsloth (optimis√© pour fine-tuning rapide)
- Donn√©es: 3031 conversations r√©elles EasyTransfert

**Contenu du notebook**:
1. Configuration environnement et v√©rification GPU
2. Installation automatique des d√©pendances
3. Chargement et pr√©traitement des donn√©es
   - Nettoyage
   - Anonymisation RGPD
   - Normalisation code-switching fran√ßais-nouchi
4. Configuration mod√®le Llama 3.2 + adaptateurs LoRA
5. Fine-tuning supervis√©
6. √âvaluation (m√©triques techniques + m√©tier)
7. Tests interactifs

**Pr√©requis GPU**: T4 (16GB) minimum, V100/A100 recommand√©

---

### 2. Architecture 2 : Deep Learning + NLP Modulaire

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AmedBah/memoire/blob/main/nouvelle_approche/notebooks/Architecture_2_DL_NLP.ipynb)

**Fichier**: `Architecture_2_DL_NLP.ipynb`

**Approche**: Syst√®me modulaire avec composants NLP sp√©cialis√©s

**Architecture**:
1. **Classification d'intentions** (BiLSTM + Attention)
2. **Named Entity Recognition** (BiLSTM-CRF)
3. **Analyse de sentiment** (CamemBERT)
4. **Dialogue State Tracking**
5. **G√©n√©ration de r√©ponses** (Templates + Retrieval + Seq2Seq)

**Contenu du notebook**:
1. Configuration environnement (CPU/GPU)
2. Installation automatique des d√©pendances
3. Chargement et pr√©traitement des donn√©es
4. Impl√©mentation des 5 modules sp√©cialis√©s
5. Pipeline complet int√©gr√©
6. √âvaluation par module et globale
7. Comparaison avec Architecture 1

**Avantage**: Fonctionne sur CPU (pas de GPU obligatoire)

---

## üöÄ Guide d'utilisation

### Ex√©cution sur Google Colab (Recommand√©)

1. **Cliquez sur le badge "Open in Colab"** dans le notebook souhait√©
2. **Connectez-vous** √† votre compte Google
3. **Activez le GPU** (pour Architecture 1):
   - Menu: `Runtime` > `Change runtime type`
   - Hardware accelerator: `GPU`
   - GPU type: `T4` (gratuit) ou `V100/A100` (Colab Pro)
4. **Ex√©cutez les cellules** dans l'ordre (`Ctrl+Enter` ou `Runtime > Run all`)
5. Le notebook va automatiquement:
   - Installer toutes les d√©pendances n√©cessaires
   - Cloner le repository et charger les donn√©es
   - Ex√©cuter le pipeline complet

### Temps d'ex√©cution estim√©s

| Architecture | GPU | Temps total |
|--------------|-----|-------------|
| Architecture 1 (Agent LLM) | T4 (16GB) | 4-5 heures |
| Architecture 1 (Agent LLM) | V100 (16GB) | 2-3 heures |
| Architecture 1 (Agent LLM) | A100 (40GB) | 1-1.5 heures |
| Architecture 2 (DL + NLP) | CPU | 2-3 heures |
| Architecture 2 (DL + NLP) | GPU | 1-2 heures |

### Donn√©es requises

Les notebooks t√©l√©chargent automatiquement les donn√©es depuis le repository GitHub:
- `conversation_1000_finetune.jsonl` (3031 conversations, ~5.2 MB)

Aucune action manuelle requise pour les donn√©es.

---

## üìä R√©sultats attendus

### Sections d'√©valuation

Chaque notebook contient des sections d'√©valuation avec des **placeholders** pour vos r√©sultats:

**M√©triques techniques**:
- BLEU-4
- ROUGE-L F1
- Perplexit√©
- Latence moyenne
- Throughput (requ√™tes/seconde)

**M√©triques m√©tier**:
- Taux de r√©solution
- Taux d'hallucination
- Net Promoter Score (NPS)
- Co√ªt d'inf√©rence

### Actions requises apr√®s ex√©cution

1. **Remplacer les r√©sultats placeholder** par vos mesures r√©elles
2. **Ajouter les captures d'√©cran** des courbes d'entra√Ænement
3. **Compl√©ter l'analyse qualitative** avec des exemples de conversations
4. **Documenter les observations** pendant l'entra√Ænement

---

## üîß D√©pannage

### Probl√®me: "CUDA out of memory"

**Solution**:
- R√©duire `per_device_train_batch_size` √† 1
- Augmenter `gradient_accumulation_steps`
- Utiliser GPU avec plus de m√©moire (Colab Pro)

### Probl√®me: Installation √©choue

**Solution**:
- Red√©marrer le runtime: `Runtime > Restart runtime`
- V√©rifier la connexion internet
- R√©ex√©cuter la cellule d'installation

### Probl√®me: Donn√©es introuvables

**Solution**:
- V√©rifier que le clone du repository a r√©ussi
- Ex√©cuter manuellement:
  ```bash
  !git clone https://github.com/AmedBah/memoire.git
  %cd memoire
  !ls conversation_1000_finetune.jsonl
  ```

---

## üìö R√©f√©rences acad√©miques

Les notebooks incluent des citations compl√®tes pour:

### Architecture 1 (Agent LLM)
1. Hu et al. (2021). LoRA: Low-Rank Adaptation of Large Language Models. ICLR 2022.
2. Touvron et al. (2023). Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288.
3. Meta AI (2024). Llama 3.2: Lightweight Open Language Models.
4. Dettmers et al. (2023). QLoRA: Efficient Finetuning of Quantized LLMs.

### Architecture 2 (DL + NLP)
1. Liu & Lane (2016). Attention-Based Recurrent Neural Network Models for Joint Intent Detection. Interspeech.
2. Lample et al. (2016). Neural Architectures for Named Entity Recognition. NAACL.
3. Martin et al. (2019). CamemBERT: a Tasty French Language Model. ACL.
4. Hochreiter & Schmidhuber (1997). Long Short-Term Memory. Neural Computation.
5. Ma & Hovy (2016). End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF. ACL.
6. Vaswani et al. (2017). Attention Is All You Need. NeurIPS.

---

## üéì Pour la soutenance

### Suggestions de pr√©sentation

1. **D√©monstration live** (5 min):
   - Ouvrir un notebook sur Colab
   - Montrer l'ex√©cution d'une cellule de g√©n√©ration
   - Tester avec une requ√™te r√©elle

2. **R√©sultats comparatifs** (3 min):
   - Pr√©senter le tableau comparatif Architecture 1 vs 2
   - Mettre en √©vidence les trade-offs
   - Justifier la recommandation (Architecture 2 pour production)

3. **Diagrammes Mermaid** (2 min):
   - Les notebooks incluent des diagrammes Mermaid
   - Copier/coller dans votre pr√©sentation
   - Expliquer le flux de traitement

---

## ‚ú® Points forts pour le jury

- ‚úÖ **Reproductibilit√©**: Notebooks ex√©cutables en 1 clic sur Colab
- ‚úÖ **Comparaison rigoureuse**: Deux approches compl√©mentaires
- ‚úÖ **Citations acad√©miques**: R√©f√©rences solides pour chaque choix
- ‚úÖ **Pr√©traitement adapt√©**: Gestion code-switching, anonymisation RGPD
- ‚úÖ **Production-ready**: Recommandations concr√®tes pour d√©ploiement
- ‚úÖ **Documentation**: Diagrammes Mermaid, commentaires d√©taill√©s

---

## üìù Notes

- Les notebooks sont **directement ex√©cutables** sans modification
- Les **placeholders sont clairement marqu√©s** avec üîπ
- Les **diagrammes Mermaid** sont int√©gr√©s dans les cellules markdown
- Le **pr√©traitement est identique** dans les deux notebooks (coh√©rence)
- Les **citations** suivent le format ACL/IEEE

---

## ü§ù Support

Pour toute question sur l'ex√©cution des notebooks:
1. V√©rifier la section **D√©pannage** ci-dessus
2. Consulter les commentaires dans les cellules du notebook
3. V√©rifier la documentation Colab: https://colab.research.google.com/

Bon travail ! üéì
