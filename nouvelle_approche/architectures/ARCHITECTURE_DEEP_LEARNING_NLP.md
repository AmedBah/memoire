# Architecture 2 : Deep Learning + NLP Classique

## Vue d'ensemble

Cette architecture adopte une approche modulaire classique de Deep Learning appliqu√©e au NLP, combinant plusieurs composants sp√©cialis√©s qui travaillent en pipeline. Contrairement √† l'approche Agent LLM end-to-end, cette architecture d√©compose le probl√®me en sous-t√¢ches distinctes (classification d'intention, extraction d'entit√©s, g√©n√©ration de r√©ponse) g√©r√©es par des mod√®les sp√©cialis√©s.

## Diagramme d'architecture (Mermaid)

```mermaid
graph TD
    A[Requ√™te Utilisateur] --> B[Pr√©traitement]
    B --> C[CamemBERT<br/>Embeddings<br/>768 dim]
    
    C --> D[Module 1:<br/>Classification Intention<br/>BiLSTM + Attention]
    C --> E[Module 2:<br/>NER<br/>BiLSTM-CRF]
    C --> F[Module 3:<br/>Sentiment Analysis<br/>CamemBERT Fine-tuned]
    
    D --> G[Module 4:<br/>Dialogue State<br/>Tracking]
    E --> G
    F --> G
    
    G --> H{Strat√©gie de<br/>G√©n√©ration}
    
    H -->|80% cas| I[Template-Based<br/>Generation]
    H -->|15% cas| J[Retrieval-Based<br/>Generation]
    H -->|5% cas| K[Seq2Seq<br/>Generation]
    
    I --> L[Post-traitement]
    J --> L
    K --> L
    
    L --> M[R√©ponse Finale]
    
    style D fill:#ffcccc,stroke:#333,stroke-width:2px
    style E fill:#ccffcc,stroke:#333,stroke-width:2px
    style F fill:#ccccff,stroke:#333,stroke-width:2px
    style G fill:#ffffcc,stroke:#333,stroke-width:3px
    style A fill:#bbf,stroke:#333,stroke-width:2px
    style M fill:#bfb,stroke:#333,stroke-width:2px
    style C fill:#ffd,stroke:#333,stroke-width:2px
```

**Flux modulaire**:
1. **Pr√©traitement** : Pipeline identique √† Architecture 1
2. **Embeddings** : CamemBERT pour repr√©sentations contextuelles
3. **Modules parall√®les** :
   - Classification d'intention (10 classes)
   - Extraction d'entit√©s (5 types)
   - Analyse de sentiment (3 classes)
4. **State Tracking** : Fusion des informations, tracking des slots
5. **G√©n√©ration** : Strat√©gie hybride selon complexit√©
6. **Post-traitement** : Formatage et v√©rifications finales

### Diagramme de pipeline de pr√©traitement (Mermaid)

```mermaid
flowchart LR
    A[Texte Brut] --> B[√âtape 1:<br/>Nettoyage de Base]
    B --> C[√âtape 2:<br/>Anonymisation RGPD]
    C --> D[√âtape 3:<br/>Normalisation Linguistique]
    D --> E[√âtape 4:<br/>Tokenisation]
    E --> F[√âtape 5:<br/>Vectorisation]
    F --> G[Donn√©es Pr√™tes]
    
    B -.-> B1[Suppression caract√®res sp√©ciaux<br/>Correction encodage UTF-8<br/>Filtrage doublons]
    C -.-> C1[Masquage num√©ros t√©l√©phone<br/>Masquage IDs transaction<br/>Conformit√© RGPD]
    D -.-> D1[Code-switching fran√ßais-nouchi<br/>Correction orthographe<br/>Normalisation casse]
    E -.-> E1[Tokenizer CamemBERT<br/>Padding/Truncation<br/>Attention masks]
    F -.-> F1[Embeddings CamemBERT<br/>768 dimensions<br/>Contextualis√©s]
    
    style B fill:#ffe6e6
    style C fill:#e6f3ff
    style D fill:#e6ffe6
    style E fill:#fff9e6
    style F fill:#f3e6ff
    style G fill:#bfb,stroke:#333,stroke-width:3px
```

## Architecture Syst√®me (Vue d√©taill√©e)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        ARCHITECTURE DEEP LEARNING + NLP CLASSIQUE              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Input: Requ√™te utilisateur en fran√ßais
   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MODULE DE PR√âTRAITEMENT            ‚îÇ
‚îÇ   - Nettoyage du texte               ‚îÇ
‚îÇ   - Normalisation                    ‚îÇ
‚îÇ   - Correction d'orthographe l√©g√®re  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   EMBEDDING LAYER                    ‚îÇ
‚îÇ   - CamemBERT embeddings (768 dim)   ‚îÇ
‚îÇ   - Contextual representations       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MODULE 1: CLASSIFICATION           ‚îÇ        ‚îÇ  MODULE 2: NER       ‚îÇ
‚îÇ   D'INTENTION                         ‚îÇ        ‚îÇ  (Extraction         ‚îÇ
‚îÇ   - Architecture: BiLSTM + Attention ‚îÇ        ‚îÇ   d'entit√©s)         ‚îÇ
‚îÇ   - Output: Intention + confidence   ‚îÇ        ‚îÇ  - BiLSTM-CRF        ‚îÇ
‚îÇ   - 5 classes principales            ‚îÇ        ‚îÇ  - Entities: ID,     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ    phone, amount,    ‚îÇ
   ‚Üì                                             ‚îÇ    operator          ‚îÇ
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚Üì                                         ‚Üì         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MODULE 3: ANALYSE DE SENTIMENT     ‚îÇ   ‚îÇ  MODULE 4: DIALOGUE     ‚îÇ
‚îÇ   - CamemBERT fine-tuned             ‚îÇ   ‚îÇ  STATE TRACKING         ‚îÇ
‚îÇ   - 3 classes: POS/NEG/NEU           ‚îÇ   ‚îÇ  - Gestion du contexte  ‚îÇ
‚îÇ   - Prioritisation requ√™tes          ‚îÇ   ‚îÇ  - Slots √† remplir      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  - Historique conv.     ‚îÇ
                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MODULE 5: GENERATION DE REPONSE                        ‚îÇ
‚îÇ   Approche hybride:                                      ‚îÇ
‚îÇ   - Templates dynamiques (80% des cas)                   ‚îÇ
‚îÇ   - Retrieval-based (15% des cas)                        ‚îÇ
‚îÇ   - Seq2Seq generation (5% cas complexes)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   POST-TRAITEMENT                    ‚îÇ
‚îÇ   - Validation coh√©rence             ‚îÇ
‚îÇ   - Insertion valeurs entit√©s        ‚îÇ
‚îÇ   - Formatage final                  ‚îÇ
‚îÇ   - Ajout √©mojis appropri√©s          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚Üì
Output: R√©ponse g√©n√©r√©e structur√©e
```

## Composants Techniques D√©taill√©s

### Module 1 : Classification d'Intention

**Objectif** : Identifier ce que l'utilisateur veut accomplir

**Taxonomie d'intentions** (5 classes principales) :
1. `INFORMATION_GENERALE` (30% du volume)
2. `PROBLEME_TRANSACTION` (40%)
3. `PROBLEME_TECHNIQUE` (15%)
4. `COMPTE_UTILISATEUR` (10%)
5. `RECLAMATION` (5%)

**Architecture Neuronale** :

```python
class IntentClassifier(nn.Module):
    def __init__(self, num_intents=5):
        super().__init__()
        
        # Embedding layer (CamemBERT frozen)
        self.embedder = CamembertModel.from_pretrained('camembert-base')
        for param in self.embedder.parameters():
            param.requires_grad = False  # Frozen
        
        # BiLSTM layers
        self.bilstm1 = nn.LSTM(
            input_size=768,      # CamemBERT dim
            hidden_size=256,
            num_layers=1,
            batch_first=True,
            bidirectional=True
        )
        
        self.bilstm2 = nn.LSTM(
            input_size=512,      # BiLSTM output
            hidden_size=128,
            num_layers=1,
            batch_first=True,
            bidirectional=True
        )
        
        # Attention mechanism
        self.attention = nn.Linear(256, 1)
        
        # Classification head
        self.dropout = nn.Dropout(0.3)
        self.fc1 = nn.Linear(256, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, num_intents)
        
    def forward(self, input_ids, attention_mask):
        # CamemBERT embeddings
        outputs = self.embedder(input_ids, attention_mask)
        sequence_output = outputs.last_hidden_state  # (batch, seq_len, 768)
        
        # BiLSTM layers
        lstm_out1, _ = self.bilstm1(sequence_output)  # (batch, seq_len, 512)
        lstm_out2, _ = self.bilstm2(lstm_out1)        # (batch, seq_len, 256)
        
        # Attention mechanism
        attention_weights = torch.softmax(
            self.attention(lstm_out2).squeeze(-1),  # (batch, seq_len)
            dim=1
        )
        context = torch.sum(
            lstm_out2 * attention_weights.unsqueeze(-1),
            dim=1
        )  # (batch, 256)
        
        # Classification
        x = self.dropout(context)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        logits = self.fc2(x)  # (batch, num_intents)
        
        return logits, attention_weights
```

**Hyperparam√®tres d'entra√Ænement** :
```python
training_config = {
    "learning_rate": 2e-5,
    "batch_size": 32,
    "epochs": 10,
    "optimizer": "AdamW",
    "loss": "CrossEntropyLoss with class weights",
    "early_stopping_patience": 3,
    "lr_scheduler": "ReduceLROnPlateau"
}
```

**Performance attendue** :
- Accuracy : 0.91-0.94
- F1-score macro : 0.89-0.92
- Latence : ~150ms
- VRAM : ~800 MB

### Module 2 : Named Entity Recognition (NER)

**Objectif** : Extraire les entit√©s cl√©s des messages

**Entit√©s √† extraire** :
- `TRANSACTION_ID` : Identifiants de transaction (TX123456, TRX789012)
- `PHONE_NUMBER` : Num√©ros de t√©l√©phone ivoiriens (07/05/01XXXXXXXX)
- `AMOUNT` : Montants en FCFA (50000, 50k, 50 mille)
- `OPERATOR` : Op√©rateurs mobile money (MTN, Orange, Moov, Wave, Tr√©sor)
- `DATE_TIME` : Dates et heures
- `PROBLEM_TYPE` : Types de probl√®mes (√©chou√©, retard, erreur)

**Architecture BiLSTM-CRF** :

```python
class NERModel(nn.Module):
    def __init__(self, num_tags):
        super().__init__()
        
        # CamemBERT embeddings
        self.embedder = CamembertModel.from_pretrained('camembert-base')
        
        # BiLSTM
        self.bilstm = nn.LSTM(
            input_size=768,
            hidden_size=256,
            num_layers=2,
            batch_first=True,
            bidirectional=True,
            dropout=0.3
        )
        
        # Projection to tag space
        self.hidden2tag = nn.Linear(512, num_tags)
        
        # CRF layer
        self.crf = CRF(num_tags, batch_first=True)
        
    def forward(self, input_ids, attention_mask, tags=None):
        # Embeddings
        outputs = self.embedder(input_ids, attention_mask)
        sequence_output = outputs.last_hidden_state
        
        # BiLSTM
        lstm_out, _ = self.bilstm(sequence_output)
        
        # Tag scores
        emissions = self.hidden2tag(lstm_out)
        
        if tags is not None:
            # Training: compute CRF loss
            loss = -self.crf(emissions, tags, mask=attention_mask.byte())
            return loss
        else:
            # Inference: Viterbi decoding
            predictions = self.crf.decode(emissions, mask=attention_mask.byte())
            return predictions
```

**Sch√©ma de tagging BIO** :
- `B-TRANSACTION_ID` : D√©but d'un ID transaction
- `I-TRANSACTION_ID` : Int√©rieur d'un ID transaction
- `B-AMOUNT` : D√©but d'un montant
- `O` : Outside (pas une entit√©)

**Exemple d'annotation** :
```
Texte: "Mon transfert TX123456 de 50000 FCFA n'est pas arriv√©"
Tags:  O    O        B-TX I-TX   O  B-AMT I-AMT O    O   O    O
```

**Post-traitement** :
```python
def extract_entities(text, predictions):
    entities = {
        "transaction_ids": [],
        "amounts": [],
        "phone_numbers": [],
        "operators": [],
        "problem_types": []
    }
    
    # Extraction √† partir des tags BIO
    current_entity = None
    current_text = []
    
    for token, tag in zip(text.split(), predictions):
        if tag.startswith("B-"):
            # Sauvegarder l'entit√© pr√©c√©dente
            if current_entity:
                save_entity(entities, current_entity, " ".join(current_text))
            # D√©marrer nouvelle entit√©
            current_entity = tag[2:]
            current_text = [token]
        elif tag.startswith("I-") and current_entity:
            current_text.append(token)
        else:
            if current_entity:
                save_entity(entities, current_entity, " ".join(current_text))
                current_entity = None
                current_text = []
    
    # Normalisation et validation
    entities["amounts"] = [normalize_amount(a) for a in entities["amounts"]]
    entities["phone_numbers"] = [validate_phone(p) for p in entities["phone_numbers"]]
    
    return entities
```

### Module 3 : Analyse de Sentiment

**Objectif** : D√©tecter l'√©motion du client (positif, n√©gatif, neutre)

**Architecture** :
```python
# Fine-tuning de CamemBERT pour sentiment
model = CamembertForSequenceClassification.from_pretrained(
    'camembert-base',
    num_labels=3  # NEG, NEU, POS
)

# Dataset d'entra√Ænement
# - 2000 messages annot√©s manuellement
# - Distribution: 40% NEG, 35% NEU, 25% POS
# - Accord inter-annotateurs: Kappa = 0.78
```

**Utilisation** :
- **Priorisation** : Messages NEGATIF ‚Üí priorit√© haute
- **Ton de r√©ponse** : Adapter empathie selon sentiment
- **Escalade** : NEGATIF + mots-cl√©s urgents ‚Üí agent humain

**Performance** :
- Accuracy : 0.88
- F1-score : 0.86 (micro), 0.84 (macro)
- Latence : ~100ms

### Module 4 : Dialogue State Tracking

**Objectif** : Maintenir le contexte conversationnel et g√©rer l'√©tat du dialogue

**√âtat du dialogue** :
```python
class DialogueState:
    def __init__(self):
        self.intent = None
        self.entities = {}
        self.sentiment = None
        self.missing_slots = []
        self.conversation_history = []
        self.turn_count = 0
        self.resolved = False
        
    def update(self, intent, entities, sentiment, user_message):
        self.intent = intent
        self.entities.update(entities)
        self.sentiment = sentiment
        self.conversation_history.append({
            "turn": self.turn_count,
            "role": "user",
            "message": user_message
        })
        self.turn_count += 1
        
        # Identifier les slots manquants
        self.missing_slots = self.identify_missing_slots()
        
    def identify_missing_slots(self):
        """Identifie les informations manquantes selon l'intention"""
        required_slots = {
            "PROBLEME_TRANSACTION": ["transaction_id", "amount", "operator"],
            "INFORMATION_GENERALE": [],
            "COMPTE_UTILISATEUR": ["phone_number"]
        }
        
        required = required_slots.get(self.intent, [])
        missing = [slot for slot in required if slot not in self.entities]
        return missing
```

**Gestion multi-tours** :
```
Tour 1:
User: "Mon transfert n'est pas arriv√©"
State: {
  intent: PROBLEME_TRANSACTION,
  entities: {},
  missing_slots: [transaction_id, amount, operator]
}
Bot: "Je comprends. Pour vous aider, j'ai besoin de votre identifiant de transaction."

Tour 2:
User: "TX123456"
State: {
  intent: PROBLEME_TRANSACTION,
  entities: {transaction_id: "TX123456"},
  missing_slots: [amount, operator]
}
Bot: "Merci. Quel √©tait le montant et entre quels op√©rateurs ?"

Tour 3:
User: "50000 FCFA de MTN vers Orange"
State: {
  intent: PROBLEME_TRANSACTION,
  entities: {
    transaction_id: "TX123456",
    amount: 50000,
    operator_from: "MTN",
    operator_to: "Orange"
  },
  missing_slots: []
}
Bot: "Parfait. Je v√©rifie le statut de votre transfert TX123456..."
```

### Module 5 : G√©n√©ration de R√©ponse

**Approche hybride** : 3 strat√©gies selon la complexit√©

#### Strat√©gie 1 : Templates dynamiques (80% des cas)

Utilis√©e pour les intentions courantes avec structure pr√©visible :

```python
templates = {
    "INFORMATION_GENERALE": {
        "demander_frais": """
Pour un transfert de {amount} FCFA, les frais sont de {fees} FCFA.
Le b√©n√©ficiaire recevra {amount} FCFA. üí∞

Les frais EasyTransfert varient entre 1% et 2% du montant :
- Minimum : 25 FCFA
- Maximum : 500 FCFA
        """,
        "demander_limites": """
Voici les limites de transfert sur EasyTransfert :

Montants :
- Minimum : 100 FCFA
- Maximum par transaction : {max_per_tx} FCFA
- Maximum quotidien : {max_per_day} FCFA

Ces limites peuvent varier selon l'op√©rateur. üìä
        """
    },
    
    "PROBLEME_TRANSACTION": {
        "transaction_incomplete": """
Je comprends votre probl√®me {emoji_empathie}.

D'apr√®s votre transaction {tx_id} :
- Montant : {amount} FCFA
- {operator_from} ‚Üí {operator_to}
- Statut actuel : {status}

{action_recommendation}

Si le probl√®me persiste, contactez notre support : 2522018730 üìû
        """
    }
}

def generate_from_template(intent, entities, context):
    template = templates[intent][context.subintent]
    
    # Calcul dynamique de variables
    if "fees" in template:
        entities["fees"] = calculate_fees(entities["amount"])
    
    # Remplissage du template
    response = template.format(**entities)
    
    return response
```

#### Strat√©gie 2 : Retrieval-based (15% des cas)

Recherche dans une base de r√©ponses pr√©-√©crites :

```python
from sentence_transformers import SentenceTransformer
import faiss

class ResponseRetriever:
    def __init__(self):
        # Mod√®le d'embedding
        self.encoder = SentenceTransformer(
            'paraphrase-multilingual-mpnet-base-v2'
        )
        
        # Base de 500 paires (question, r√©ponse) pr√©-√©crites
        self.responses_db = load_responses_database()
        
        # Index FAISS pour recherche rapide
        self.index = self.build_faiss_index()
    
    def retrieve(self, query, k=3):
        # Vectoriser la requ√™te
        query_vector = self.encoder.encode([query])
        
        # Recherche des k plus proches
        distances, indices = self.index.search(query_vector, k)
        
        # Retourner la meilleure r√©ponse
        best_idx = indices[0][0]
        best_response = self.responses_db[best_idx]["response"]
        confidence = 1 / (1 + distances[0][0])  # Normalisation
        
        return best_response, confidence
```

#### Strat√©gie 3 : Seq2Seq Generation (5% cas complexes)

Pour les cas non couverts par templates ou retrieval :

```python
class Seq2SeqGenerator(nn.Module):
    def __init__(self):
        super().__init__()
        
        # Encoder: CamemBERT
        self.encoder = CamembertModel.from_pretrained('camembert-base')
        
        # Decoder: LSTM with attention
        self.decoder = nn.LSTM(
            input_size=768 + 256,  # encoder output + prev hidden
            hidden_size=512,
            num_layers=2,
            batch_first=True
        )
        
        # Attention
        self.attention = BahdanauAttention(512, 768)
        
        # Output projection
        self.output_proj = nn.Linear(512, vocab_size)
        
    def forward(self, input_ids, target_ids=None):
        # Encoder
        encoder_outputs = self.encoder(input_ids).last_hidden_state
        
        # Decoder with attention (beam search inference)
        if target_ids is None:
            # Inference mode
            generated = self.beam_search(encoder_outputs, beam_size=3)
            return generated
        else:
            # Training mode
            loss = self.teacher_forcing(encoder_outputs, target_ids)
            return loss
```

**S√©lection de strat√©gie** :
```python
def select_generation_strategy(intent, entities, dialogue_state):
    # Strat√©gie 1: Templates (prioritaire)
    if has_template(intent) and all_slots_filled(entities):
        return "template"
    
    # Strat√©gie 2: Retrieval
    elif intent in ["INFORMATION_GENERALE", "FAQ"]:
        return "retrieval"
    
    # Strat√©gie 3: Seq2Seq (fallback)
    else:
        return "seq2seq"
```

### Post-traitement

**Validation et enrichissement** :
```python
def post_process(response, entities, sentiment):
    # 1. Validation de coh√©rence
    if not is_coherent(response):
        response = fallback_response()
    
    # 2. Insertion des valeurs d'entit√©s
    response = insert_entity_values(response, entities)
    
    # 3. Ajout d'√©mojis appropri√©s
    emoji_map = {
        "POSITIF": "üòä ‚úÖ üëç",
        "NEGATIF": "üòü üôè",
        "NEUTRE": "üìä üí∞ üìû"
    }
    response = add_emojis(response, sentiment, emoji_map)
    
    # 4. Formatage final
    response = format_response(response)
    
    # 5. Ajout de call-to-action si n√©cessaire
    if needs_followup(response):
        response += "\n\nPuis-je vous aider avec autre chose ? üòä"
    
    return response
```

## Pipeline Complet : Exemple

**Input** : "Bonjour, mon transfert de 75000 vers Orange n'est pas arriv√©"

**√âtape 1 : Pr√©traitement**
```
Texte nettoy√©: "bonjour mon transfert de 75000 vers orange n'est pas arriv√©"
```

**√âtape 2 : Embedding (CamemBERT)**
```
Shape: (1, seq_len, 768)
```

**√âtape 3 : Classification d'intention**
```
Intent: PROBLEME_TRANSACTION (confidence: 0.96)
Sub-intent: transaction_incomplete
```

**√âtape 4 : NER**
```
Entities extracted:
- amount: 75000
- operator_to: "Orange"

Missing entities:
- transaction_id
- operator_from
```

**√âtape 5 : Analyse de sentiment**
```
Sentiment: NEGATIF (confidence: 0.89)
‚Üí Priorit√©: HAUTE
```

**√âtape 6 : Dialogue State Tracking**
```
State:
  turn: 1
  intent: PROBLEME_TRANSACTION
  entities: {amount: 75000, operator_to: "Orange"}
  missing_slots: [transaction_id, operator_from]
  sentiment: NEGATIF
```

**√âtape 7 : G√©n√©ration (Template)**
```python
template = """
Je comprends votre inqui√©tude {emoji} et je vais vous aider.

Pour localiser votre transfert de {amount} FCFA vers {operator_to}, 
j'ai besoin de :
1. Votre identifiant de transaction (commence par TX ou TRX)
2. L'op√©rateur d'envoi

Pouvez-vous me fournir ces informations ?
"""

response = template.format(
    emoji="üòü",
    amount="75 000",
    operator_to="Orange"
)
```

**√âtape 8 : Post-traitement**
```
Ajout signature: "\n\nMerci de votre patience. üôè"
```

**Output final** :
```
Je comprends votre inqui√©tude üòü et je vais vous aider.

Pour localiser votre transfert de 75 000 FCFA vers Orange, 
j'ai besoin de :
1. Votre identifiant de transaction (commence par TX ou TRX)
2. L'op√©rateur d'envoi

Pouvez-vous me fournir ces informations ?

Merci de votre patience. üôè
```

**Latence totale : ~400ms**

## Avantages et Limites

### Avantages ‚úÖ

1. **Contr√¥le et pr√©visibilit√©** :
   - Comportement d√©terministe et contr√¥lable
   - Pas de risque d'hallucination
   - Debugging facile (chaque module test√© ind√©pendamment)

2. **Performance et efficacit√©** :
   - Latence faible (~400ms vs 2-3s pour LLM)
   - Co√ªt d'inf√©rence r√©duit (CPU possible pour certains modules)
   - Scalabilit√© √©lev√©e (>10 req/s sur CPU)

3. **Modularit√©** :
   - Remplacement/am√©lioration d'un module sans tout refaire
   - R√©utilisation de modules pour d'autres projets
   - Tests unitaires par module

4. **Robustesse** :
   - Gestion d'erreurs fine par module
   - Fallback strategies √† chaque √©tape
   - Performance stable et reproductible

5. **Tra√ßabilit√©** :
   - Logs d√©taill√©s de chaque d√©cision
   - Explications faciles (quel module a fait quoi)
   - Conformit√© et audit facilit√©s

### Limites ‚ùå

1. **Complexit√© de d√©veloppement** :
   - Multiple mod√®les √† entra√Æner et maintenir
   - Pipeline complexe avec nombreuses d√©pendances
   - Temps de d√©veloppement initial long

2. **Flexibilit√© limit√©e** :
   - Difficult√© √† g√©rer les cas impr√©vus
   - N√©cessite des templates pour chaque intention
   - Moins naturel que la g√©n√©ration LLM

3. **Maintenance** :
   - Mise √† jour de multiples mod√®les
   - Gestion de versions complexe
   - Drift de performance √† surveiller par module

4. **Propagation d'erreurs** :
   - Erreur en amont affecte tous les modules suivants
   - N√©cessit√© de seuils de confiance bien calibr√©s
   - Gestion des cas ambigus d√©licate

5. **Coverage limit√©e** :
   - Templates couvrent 80% des cas, les 20% restants probl√©matiques
   - Seq2Seq g√©n√©ration moins performante qu'un LLM
   - N√©cessite enrichissement continu de la base de templates

## M√©triques de Performance

### Performances par module

| Module | Accuracy | F1-Score | Latence | VRAM |
|--------|----------|----------|---------|------|
| Intent Classification | 0.92 | 0.90 | 150ms | 800MB |
| NER | 0.89 (F1) | 0.89 | 120ms | 1GB |
| Sentiment Analysis | 0.88 | 0.86 | 100ms | 800MB |
| Response Generation (avg) | - | - | 50-200ms | Varies |
| **TOTAL PIPELINE** | - | - | **~400ms** | **2.5GB** |

### M√©triques m√©tier (simul√©es)

| M√©trique | Valeur |
|----------|--------|
| Taux de r√©solution correct | 85% |
| Satisfaction (1-5) | 4.0 |
| N√©cessite intervention humaine | 15% |
| Hallucinations | 0% (pas de g√©n√©ration libre) |
| Coh√©rence des r√©ponses | 95% |

### M√©triques op√©rationnelles

| M√©trique | CPU (8 cores) | GPU T4 |
|----------|---------------|--------|
| Throughput (req/s) | 2.5 | 8 |
| Latence p50 | 400ms | 350ms |
| Latence p95 | 600ms | 450ms |
| Co√ªt par 1M requ√™tes | $5 | $12 |

## Recommandations d'Usage

**‚úÖ Utiliser cette architecture si** :
- N√©cessit√© de garanties strictes (z√©ro hallucination)
- Latence critique (<500ms)
- Budget infrastructure limit√©
- Volume √©lev√© de requ√™tes
- Tra√ßabilit√© et explainability critiques
- Cas d'usage bien d√©finis et stables

**‚ùå √âviter cette architecture si** :
- Requ√™tes tr√®s vari√©es et impr√©visibles
- Besoin de flexibilit√© maximale
- √âquipe r√©duite (maintenance complexe)
- √âvolution rapide des cas d'usage
- Contexte linguistique tr√®s vari√©

## Conclusion

L'architecture Deep Learning + NLP classique offre une solution robuste, contr√¥lable et efficace pour l'automatisation du service client d'EasyTransfert. Sa nature modulaire permet un contr√¥le fin et une pr√©visibilit√© excellente, au prix d'une complexit√© de d√©veloppement et de maintenance plus √©lev√©e.

Cette architecture est particuli√®rement recommand√©e pour les environnements de production n√©cessitant des garanties strictes, une latence faible et une scalabilit√© √©lev√©e, o√π les cas d'usage sont bien d√©finis et relativement stables.
