# ğŸš€ Guide d'Utilisation sur Google Colab Pro

Ce guide vous explique comment exÃ©cuter les notebooks d'architectures expÃ©rimentales sur Google Colab Pro.

## ğŸ“‹ Table des MatiÃ¨res

1. [PrÃ©requis](#prÃ©requis)
2. [Configuration Initiale](#configuration-initiale)
3. [Lancement des Notebooks](#lancement-des-notebooks)
4. [Choix du Runtime](#choix-du-runtime)
5. [Gestion des DonnÃ©es](#gestion-des-donnÃ©es)
6. [Optimisation pour Colab Pro](#optimisation-pour-colab-pro)
7. [RÃ©solution de ProblÃ¨mes](#rÃ©solution-de-problÃ¨mes)
8. [Conseils et Bonnes Pratiques](#conseils-et-bonnes-pratiques)

---

## ğŸ¯ PrÃ©requis

### Compte Google Colab Pro

**Pourquoi Colab Pro ?**
- GPU plus puissants (V100, A100 vs T4 gratuit)
- Plus de RAM (jusqu'Ã  32 GB vs 12 GB)
- Sessions plus longues (24h vs 12h)
- PrioritÃ© d'accÃ¨s aux ressources
- Essentiel pour l'entraÃ®nement de modÃ¨les 3B

**Tarification:**
- Colab Pro: ~$9.99/mois
- Colab Pro+: ~$49.99/mois (recommandÃ© pour Architecture 1)

### Authentification HuggingFace

Les modÃ¨les Llama 3.2 nÃ©cessitent une authentification:

1. CrÃ©er un compte sur [HuggingFace](https://huggingface.co/)
2. Accepter les conditions d'utilisation de [Llama 3.2](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)
3. CrÃ©er un token d'accÃ¨s: [Settings > Access Tokens](https://huggingface.co/settings/tokens)
4. Conserver le token pour l'authentification dans les notebooks

---

## âš™ï¸ Configuration Initiale

### 1. Ouvrir un Notebook

Chaque notebook dispose d'un badge "Open in Colab" :

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AmedBah/memoire/blob/main/notebooks/architecture_1/01_architecture_1_simple_agent_finetuning.ipynb)

**Ou bien:**
1. Aller sur [Google Colab](https://colab.research.google.com/)
2. File > Open notebook > GitHub
3. Entrer: `AmedBah/memoire`
4. SÃ©lectionner le notebook dÃ©sirÃ©

### 2. VÃ©rifier le Runtime

**Cellule de vÃ©rification automatique** (dÃ©jÃ  incluse dans les notebooks):
```python
# DÃ©tection automatique de l'environnement
IS_COLAB = 'google.colab' in sys.modules
```

Cette cellule affiche:
- âœ“ Type d'environnement (Colab ou local)
- âœ“ GPU disponible et sa mÃ©moire
- âš ï¸ Avertissements si configuration inadÃ©quate

---

## ğŸ® Lancement des Notebooks

### Architecture 1: Agent Simple (Fine-tuning)

**Notebook:** `01_architecture_1_simple_agent_finetuning.ipynb`

**Runtime recommandÃ©:**
- GPU: V100 (16 GB) ou A100 (40 GB)
- RAM: High-RAM (32 GB)
- DurÃ©e estimÃ©e: 2-4 heures

**Ã‰tapes:**
1. Cliquer sur le badge Colab ou ouvrir le notebook
2. Runtime > Change runtime type > GPU (V100 ou mieux)
3. ExÃ©cuter les cellules de configuration Colab
4. Authentifier HuggingFace quand demandÃ©
5. Lancer l'entraÃ®nement

**DonnÃ©es utilisÃ©es:**
- `data/conversations/conversation_1000_finetune.jsonl`
- `data/expressions/expressions_ivoiriennes.json`

---

### Architecture 2: RAG Standard

**Notebook:** `02_architecture_2_rag_standard.ipynb`

**Runtime recommandÃ©:**
- GPU: T4 (16 GB) suffisant
- RAM: Standard (12 GB) ou High-RAM
- DurÃ©e estimÃ©e: 30-60 minutes

**Ã‰tapes:**
1. Ouvrir le notebook sur Colab
2. Runtime > Change runtime type > GPU
3. ExÃ©cuter les cellules de configuration
4. Initialiser ChromaDB
5. Indexer les donnÃ©es
6. Tester les requÃªtes RAG

**DonnÃ©es utilisÃ©es:**
- `data/faqs/faq_easytransfert.json`
- `data/operators/operators_info.json`
- `data/procedures/procedures_resolution.json`
- `data/documents/doc.txt.txt`

---

### Architecture 3: RAG-Agentique

**Notebook:** `03_architecture_3_rag_agentique.ipynb`

**Runtime recommandÃ©:**
- GPU: V100 (16 GB) recommandÃ©
- RAM: High-RAM (25 GB)
- DurÃ©e estimÃ©e: 1-2 heures

**Ã‰tapes:**
1. Ouvrir le notebook sur Colab
2. Runtime > Change runtime type > GPU (V100)
3. ExÃ©cuter les cellules de configuration
4. Charger tous les outils (RAG Retriever, Operator Info, etc.)
5. Initialiser l'agent ReAct
6. Tester les scÃ©narios

**DonnÃ©es utilisÃ©es:**
- Toutes les donnÃ©es des Architectures 1 et 2
- `data/documents/transaction_logs_sample.json`

---

## ğŸ›ï¸ Choix du Runtime

### Comment changer le runtime ?

1. Menu: **Runtime > Change runtime type**
2. Choisir les paramÃ¨tres:
   - **Hardware accelerator**: GPU
   - **GPU type** (Colab Pro uniquement):
     - Standard: T4 (16 GB VRAM)
     - Premium: V100 (16 GB) ou A100 (40 GB)
   - **Runtime shape**:
     - Standard: 12 GB RAM
     - High-RAM: 25-32 GB RAM

### Recommandations par Architecture

| Architecture | GPU Minimum | GPU RecommandÃ© | RAM | DurÃ©e |
|-------------|-------------|----------------|-----|-------|
| Architecture 1 | T4 (16 GB) | V100/A100 | High-RAM | 2-4h |
| Architecture 2 | T4 (16 GB) | T4/V100 | Standard | 30-60min |
| Architecture 3 | T4 (16 GB) | V100 | High-RAM | 1-2h |

### VÃ©rification GPU

AprÃ¨s avoir changÃ© le runtime, exÃ©cutez:
```python
import torch
print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"MÃ©moire: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
```

---

## ğŸ’¾ Gestion des DonnÃ©es

### Option 1: Clonage Automatique du Repository (RecommandÃ©)

**DÃ©jÃ  configurÃ© dans les notebooks!**

```python
# Automatique dans la cellule de configuration
!git clone https://github.com/AmedBah/memoire.git /content/memoire
DATA_DIR = '/content/memoire/data'
```

**Avantages:**
- âœ… Simple et automatique
- âœ… Pas besoin de Google Drive
- âœ… DonnÃ©es toujours Ã  jour

**InconvÃ©nients:**
- âš ï¸ Re-tÃ©lÃ©chargement Ã  chaque session (~6 MB)
- âš ï¸ Perdu si session se termine

---

### Option 2: Google Drive (Pour RÃ©sultats Persistants)

**Pour sauvegarder modÃ¨les et rÃ©sultats:**

```python
# Monter Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Copier les donnÃ©es dans Drive (une seule fois)
!cp -r /content/memoire/data /content/drive/MyDrive/memoire/

# Utiliser Drive comme rÃ©pertoire de donnÃ©es
DATA_DIR = '/content/drive/MyDrive/memoire/data'
```

**Avantages:**
- âœ… DonnÃ©es persistantes entre sessions
- âœ… Sauvegarde des modÃ¨les entraÃ®nÃ©s
- âœ… Partage facile

**InconvÃ©nients:**
- âš ï¸ Plus lent (accÃ¨s rÃ©seau)
- âš ï¸ NÃ©cessite espace Drive

---

### Structure des DonnÃ©es

```
data/
â”œâ”€â”€ conversations/          # 6.4 MB - DonnÃ©es conversationnelles
â”œâ”€â”€ documents/             # 65 KB - Documentation et logs
â”œâ”€â”€ faqs/                  # ~3 KB - Questions-rÃ©ponses
â”œâ”€â”€ operators/             # ~5 KB - Infos opÃ©rateurs
â”œâ”€â”€ procedures/            # ~4 KB - ProcÃ©dures rÃ©solution
â””â”€â”€ expressions/           # ~2 KB - Expressions ivoiriennes
```

**Total:** ~6.5 MB (tÃ©lÃ©chargement rapide)

---

## âš¡ Optimisation pour Colab Pro

### 1. GÃ©rer les Timeouts

**Sessions Colab:**
- Gratuit: 12 heures max
- Pro: 24 heures max
- Pro+: 24 heures avec moins d'interruptions

**Pour les entraÃ®nements longs:**

```python
# Sauvegarder rÃ©guliÃ¨rement les checkpoints
training_args = TrainingArguments(
    output_dir="/content/drive/MyDrive/memoire/checkpoints",
    save_strategy="steps",
    save_steps=500,  # Sauvegarder tous les 500 steps
    save_total_limit=3,  # Garder seulement les 3 derniers
)
```

---

### 2. Optimiser la MÃ©moire GPU

**Pour Ã©viter les OOM (Out of Memory):**

```python
# Architecture 1: RÃ©duire batch_size si nÃ©cessaire
per_device_train_batch_size = 2  # Au lieu de 4
gradient_accumulation_steps = 8  # Compenser

# Architecture 2: RÃ©duire chunk_size
chunk_size = 256  # Au lieu de 512

# Architecture 3: Charger le modÃ¨le en 4-bit
load_in_4bit = True
```

---

### 3. Monitoring avec Weights & Biases

**DÃ©jÃ  intÃ©grÃ© dans les notebooks:**

```python
import wandb

# Se connecter (premiÃ¨re fois)
wandb.login()

# Tracking automatique
wandb.init(project="easytransfert-architectures")
```

**Avantages:**
- ğŸ“Š Visualisation en temps rÃ©el
- ğŸ“ˆ Courbes d'entraÃ®nement
- ğŸ’¾ Sauvegarde automatique des mÃ©triques
- ğŸ”— AccÃ¨s depuis n'importe oÃ¹

---

### 4. Utiliser les GPU Efficacement

**Nettoyer la mÃ©moire entre exÃ©cutions:**

```python
import torch
import gc

# LibÃ©rer la mÃ©moire GPU
torch.cuda.empty_cache()
gc.collect()
```

**VÃ©rifier l'utilisation:**

```python
# Pendant l'entraÃ®nement
print(f"MÃ©moire utilisÃ©e: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
print(f"MÃ©moire rÃ©servÃ©e: {torch.cuda.memory_reserved() / 1e9:.2f} GB")
```

---

## ğŸ”§ RÃ©solution de ProblÃ¨mes

### Erreur: "Runtime disconnected"

**Causes:**
- Session inactive trop longtemps
- DÃ©passement du quota GPU
- Erreur dans le code

**Solutions:**
1. Runtime > Reconnect
2. RÃ©exÃ©cuter les cellules depuis le dÃ©but
3. VÃ©rifier les logs pour erreurs

---

### Erreur: "Out of Memory (OOM)"

**Message:** `CUDA out of memory`

**Solutions:**

```python
# 1. RÃ©duire batch_size
per_device_train_batch_size = 1
gradient_accumulation_steps = 16

# 2. Utiliser gradient checkpointing
use_gradient_checkpointing = True

# 3. RÃ©duire max_seq_length
max_seq_length = 1024  # Au lieu de 2048

# 4. Activer quantification
load_in_4bit = True
```

---

### Erreur: "No GPU available"

**Cause:** Runtime CPU sÃ©lectionnÃ©

**Solution:**
1. Runtime > Change runtime type
2. Hardware accelerator > GPU
3. Save
4. Runtime > Restart runtime

---

### Erreur: "Cannot access HuggingFace model"

**Message:** `GatedRepoError` ou `401 Unauthorized`

**Solutions:**
1. Accepter les conditions: [Llama 3.2](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)
2. CrÃ©er un token: [Settings > Tokens](https://huggingface.co/settings/tokens)
3. Authentifier:
   ```python
   from huggingface_hub import login
   login(token="your_token_here")
   ```

---

### Erreur: "Module not found"

**Cause:** DÃ©pendance manquante

**Solution:**

```python
# Installer la dÃ©pendance
!pip install -q package_name

# Ou rÃ©installer toutes les dÃ©pendances
!pip install -q -r /content/memoire/requirements.txt
```

---

## ğŸ’¡ Conseils et Bonnes Pratiques

### 1. Gestion des Sessions

âœ… **Ã€ faire:**
- Sauvegarder rÃ©guliÃ¨rement (Drive ou W&B)
- Utiliser des checkpoints
- ExÃ©cuter cellule par cellule pour dÃ©boguer
- VÃ©rifier GPU avant entraÃ®nement long

âŒ **Ã€ Ã©viter:**
- Laisser session inactive (timeout)
- EntraÃ®ner sans sauvegardes
- Ignorer les warnings de mÃ©moire
- ExÃ©cuter plusieurs notebooks en parallÃ¨le

---

### 2. Optimisation des CoÃ»ts

**Colab Pro ($9.99/mois):**
- Architecture 2 et 3 fonctionnent bien
- Architecture 1 possible mais plus lent

**Colab Pro+ ($49.99/mois):**
- RecommandÃ© pour Architecture 1 (fine-tuning)
- A100 GPU pour entraÃ®nement rapide
- Sessions plus longues et stables

**Astuce:** Commencer avec Pro, passer Ã  Pro+ si nÃ©cessaire

---

### 3. Organisation du Travail

**Structure recommandÃ©e dans Drive:**
```
MyDrive/
â””â”€â”€ memoire/
    â”œâ”€â”€ data/                # DonnÃ©es (copiÃ© une fois)
    â”œâ”€â”€ checkpoints/         # Checkpoints d'entraÃ®nement
    â”œâ”€â”€ models/              # ModÃ¨les finaux
    â”œâ”€â”€ outputs/             # RÃ©sultats et logs
    â””â”€â”€ notebooks/           # Notebooks modifiÃ©s (optionnel)
```

---

### 4. Workflow RecommandÃ©

**Session Typique:**

1. **PrÃ©paration (5 min)**
   - Ouvrir notebook
   - VÃ©rifier runtime (GPU, RAM)
   - Monter Drive si nÃ©cessaire
   - Cloner repository

2. **ExÃ©cution (30 min - 4h)**
   - ExÃ©cuter cellules de configuration
   - Lancer entraÃ®nement/expÃ©riences
   - Monitorer avec W&B

3. **Sauvegarde (5 min)**
   - Sauvegarder modÃ¨le dans Drive
   - Exporter mÃ©triques
   - TÃ©lÃ©charger rÃ©sultats importants

4. **Nettoyage**
   - ArrÃªter runtime si terminÃ©
   - LibÃ©rer ressources pour autres utilisateurs

---

## ğŸ“Š MÃ©triques de Performance Attendues

### Architecture 1 (Fine-tuning)

**Avec V100 (Colab Pro):**
- Temps par epoch: ~30-45 minutes
- Epochs recommandÃ©s: 3-5
- DurÃ©e totale: 2-3 heures
- MÃ©moire GPU: ~12-14 GB

**Avec A100 (Colab Pro+):**
- Temps par epoch: ~15-20 minutes
- DurÃ©e totale: 1-1.5 heures
- MÃ©moire GPU: ~12-14 GB

---

### Architecture 2 (RAG)

**Avec T4:**
- Indexation: ~5-10 minutes
- RequÃªte RAG: ~2-3 secondes
- MÃ©moire GPU: ~6-8 GB

---

### Architecture 3 (RAG-Agentique)

**Avec V100:**
- Configuration: ~10-15 minutes
- Cycle ReAct: ~3-5 secondes
- MÃ©moire GPU: ~8-10 GB

---

## ğŸ“ Ressources SupplÃ©mentaires

### Documentation
- [Google Colab FAQ](https://research.google.com/colaboratory/faq.html)
- [Colab Pro Features](https://colab.research.google.com/signup)
- [HuggingFace Authentication](https://huggingface.co/docs/hub/security-tokens)
- [Weights & Biases Guide](https://docs.wandb.ai/guides)

### CommunautÃ©
- [GitHub Repository](https://github.com/AmedBah/memoire)
- [Issues](https://github.com/AmedBah/memoire/issues)
- Support EasyTransfert: 2522018730

---

## ğŸ“ Support

Pour toute question ou problÃ¨me:

1. VÃ©rifier ce guide
2. Consulter les [Issues GitHub](https://github.com/AmedBah/memoire/issues)
3. CrÃ©er une nouvelle issue si nÃ©cessaire
4. Contacter: support@easytransfert.ci

---

**Bon entraÃ®nement sur Colab Pro! ğŸš€**

*DerniÃ¨re mise Ã  jour: 2024-10-12*
