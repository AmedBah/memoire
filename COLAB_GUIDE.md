# üöÄ Guide d'Utilisation sur Google Colab Pro

Ce guide vous explique comment ex√©cuter les notebooks d'architectures exp√©rimentales sur Google Colab Pro.

## üìã Table des Mati√®res

1. [Pr√©requis](#pr√©requis)
2. [Configuration Initiale](#configuration-initiale)
3. [Lancement des Notebooks](#lancement-des-notebooks)
4. [Choix du Runtime](#choix-du-runtime)
5. [Gestion des Donn√©es](#gestion-des-donn√©es)
6. [Optimisation pour Colab Pro](#optimisation-pour-colab-pro)
7. [R√©solution de Probl√®mes](#r√©solution-de-probl√®mes)
8. [Conseils et Bonnes Pratiques](#conseils-et-bonnes-pratiques)

---

## üéØ Pr√©requis

### Compte Google Colab Pro

**Pourquoi Colab Pro ?**
- GPU plus puissants (V100, A100 vs T4 gratuit)
- Plus de RAM (jusqu'√† 32 GB vs 12 GB)
- Sessions plus longues (24h vs 12h)
- Priorit√© d'acc√®s aux ressources
- Essentiel pour l'entra√Ænement de mod√®les 3B

**Tarification:**
- Colab Pro: ~$9.99/mois
- Colab Pro+: ~$49.99/mois (recommand√© pour Architecture 1)

### Authentification HuggingFace

Les mod√®les Llama 3.2 n√©cessitent une authentification:

1. Cr√©er un compte sur [HuggingFace](https://huggingface.co/)
2. Accepter les conditions d'utilisation de [Llama 3.2](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)
3. Cr√©er un token d'acc√®s: [Settings > Access Tokens](https://huggingface.co/settings/tokens)
4. Conserver le token pour l'authentification dans les notebooks

---

## ‚öôÔ∏è Configuration Initiale

### 1. Ouvrir un Notebook

Chaque notebook dispose d'un badge "Open in Colab" :

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AmedBah/memoire/blob/main/notebooks/architecture_1/01_architecture_1_simple_agent_finetuning.ipynb)

**Ou bien:**
1. Aller sur [Google Colab](https://colab.research.google.com/)
2. File > Open notebook > GitHub
3. Entrer: `AmedBah/memoire`
4. S√©lectionner le notebook d√©sir√©

### 2. V√©rifier le Runtime

**Cellule de v√©rification automatique** (d√©j√† incluse dans les notebooks):
```python
# D√©tection automatique de l'environnement
IS_COLAB = 'google.colab' in sys.modules
```

Cette cellule affiche:
- ‚úì Type d'environnement (Colab ou local)
- ‚úì GPU disponible et sa m√©moire
- ‚ö†Ô∏è Avertissements si configuration inad√©quate

---

## üéÆ Lancement des Notebooks

### Architecture 1: Agent Simple (Fine-tuning)

**Notebook:** `01_architecture_1_simple_agent_finetuning.ipynb`

**Runtime recommand√©:**
- GPU: V100 (16 GB) ou A100 (40 GB)
- RAM: High-RAM (32 GB)
- Dur√©e estim√©e: 2-4 heures

**√âtapes:**
1. Cliquer sur le badge Colab ou ouvrir le notebook
2. Runtime > Change runtime type > GPU (V100 ou mieux)
3. Ex√©cuter les cellules de configuration Colab
4. Authentifier HuggingFace quand demand√©
5. Lancer l'entra√Ænement

**Donn√©es utilis√©es:**
- `data/conversations/conversation_1000_finetune.jsonl`
- `data/expressions/expressions_ivoiriennes.json`

---

### Architecture 2: RAG Standard

**Notebook:** `02_architecture_2_rag_standard.ipynb`

**Runtime recommand√©:**
- GPU: T4 (16 GB) suffisant
- RAM: Standard (12 GB) ou High-RAM
- Dur√©e estim√©e: 30-60 minutes

**√âtapes:**
1. Ouvrir le notebook sur Colab
2. Runtime > Change runtime type > GPU
3. Ex√©cuter les cellules de configuration
4. Initialiser ChromaDB
5. Indexer les donn√©es
6. Tester les requ√™tes RAG

**Donn√©es utilis√©es:**
- `data/faqs/faq_easytransfert.json`
- `data/operators/operators_info.json`
- `data/procedures/procedures_resolution.json`
- `data/documents/doc.txt.txt`

---

### Architecture 3: RAG-Agentique

**Notebook:** `03_architecture_3_rag_agentique.ipynb`

**Runtime recommand√©:**
- GPU: V100 (16 GB) recommand√©
- RAM: High-RAM (25 GB)
- Dur√©e estim√©e: 1-2 heures

**√âtapes:**
1. Ouvrir le notebook sur Colab
2. Runtime > Change runtime type > GPU (V100)
3. Ex√©cuter les cellules de configuration
4. Charger tous les outils (RAG Retriever, Operator Info, etc.)
5. Initialiser l'agent ReAct
6. Tester les sc√©narios

**Donn√©es utilis√©es:**
- Toutes les donn√©es des Architectures 1 et 2
- `data/documents/transaction_logs_sample.json`

---

## üéõÔ∏è Choix du Runtime

### Comment changer le runtime ?

1. Menu: **Runtime > Change runtime type**
2. Choisir les param√®tres:
   - **Hardware accelerator**: GPU
   - **GPU type** (Colab Pro uniquement):
     - Standard: T4 (16 GB VRAM)
     - Premium: V100 (16 GB) ou A100 (40 GB)
   - **Runtime shape**:
     - Standard: 12 GB RAM
     - High-RAM: 25-32 GB RAM

### Recommandations par Architecture

| Architecture | GPU Minimum | GPU Recommand√© | RAM | Dur√©e |
|-------------|-------------|----------------|-----|-------|
| Architecture 1 | T4 (16 GB) | V100/A100 | High-RAM | 2-4h |
| Architecture 2 | T4 (16 GB) | T4/V100 | Standard | 30-60min |
| Architecture 3 | T4 (16 GB) | V100 | High-RAM | 1-2h |

### V√©rification GPU

Apr√®s avoir chang√© le runtime, ex√©cutez:
```python
import torch
print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"M√©moire: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
```

---

## üíæ Gestion des Donn√©es

### Option 1: Clonage Automatique du Repository (Recommand√©)

**D√©j√† configur√© dans les notebooks!**

```python
# Automatique dans la cellule de configuration
!git clone https://github.com/AmedBah/memoire.git /content/memoire
DATA_DIR = '/content/memoire/data'
```

**Avantages:**
- ‚úÖ Simple et automatique
- ‚úÖ Pas besoin de Google Drive
- ‚úÖ Donn√©es toujours √† jour

**Inconv√©nients:**
- ‚ö†Ô∏è Re-t√©l√©chargement √† chaque session (~6 MB)
- ‚ö†Ô∏è Perdu si session se termine

---

### Option 2: Google Drive (Pour R√©sultats Persistants)

**Pour sauvegarder mod√®les et r√©sultats:**

```python
# Monter Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Copier les donn√©es dans Drive (une seule fois)
!cp -r /content/memoire/data /content/drive/MyDrive/memoire/

# Utiliser Drive comme r√©pertoire de donn√©es
DATA_DIR = '/content/drive/MyDrive/memoire/data'
```

**Avantages:**
- ‚úÖ Donn√©es persistantes entre sessions
- ‚úÖ Sauvegarde des mod√®les entra√Æn√©s
- ‚úÖ Partage facile

**Inconv√©nients:**
- ‚ö†Ô∏è Plus lent (acc√®s r√©seau)
- ‚ö†Ô∏è N√©cessite espace Drive

---

### Structure des Donn√©es

```
data/
‚îú‚îÄ‚îÄ conversations/          # 6.4 MB - Donn√©es conversationnelles
‚îú‚îÄ‚îÄ documents/             # 65 KB - Documentation et logs
‚îú‚îÄ‚îÄ faqs/                  # ~3 KB - Questions-r√©ponses
‚îú‚îÄ‚îÄ operators/             # ~5 KB - Infos op√©rateurs
‚îú‚îÄ‚îÄ procedures/            # ~4 KB - Proc√©dures r√©solution
‚îî‚îÄ‚îÄ expressions/           # ~2 KB - Expressions ivoiriennes
```

**Total:** ~6.5 MB (t√©l√©chargement rapide)

---

## ‚ö° Optimisation pour Colab Pro

### 1. G√©rer les Timeouts

**Sessions Colab:**
- Gratuit: 12 heures max
- Pro: 24 heures max
- Pro+: 24 heures avec moins d'interruptions

**Pour les entra√Ænements longs:**

```python
# Sauvegarder r√©guli√®rement les checkpoints
training_args = TrainingArguments(
    output_dir="/content/drive/MyDrive/memoire/checkpoints",
    save_strategy="steps",
    save_steps=500,  # Sauvegarder tous les 500 steps
    save_total_limit=3,  # Garder seulement les 3 derniers
)
```

---

### 2. Optimiser la M√©moire GPU

**Pour √©viter les OOM (Out of Memory):**

```python
# Architecture 1: R√©duire batch_size si n√©cessaire
per_device_train_batch_size = 2  # Au lieu de 4
gradient_accumulation_steps = 8  # Compenser

# Architecture 2: R√©duire chunk_size
chunk_size = 256  # Au lieu de 512

# Architecture 3: Charger le mod√®le en 4-bit
load_in_4bit = True
```

---

### 3. Monitoring avec Weights & Biases

**D√©j√† int√©gr√© dans les notebooks:**

```python
import wandb

# Se connecter (premi√®re fois)
wandb.login()

# Tracking automatique
wandb.init(project="easytransfert-architectures")
```

**Avantages:**
- üìä Visualisation en temps r√©el
- üìà Courbes d'entra√Ænement
- üíæ Sauvegarde automatique des m√©triques
- üîó Acc√®s depuis n'importe o√π

---

### 4. Utiliser les GPU Efficacement

**Nettoyer la m√©moire entre ex√©cutions:**

```python
import torch
import gc

# Lib√©rer la m√©moire GPU
torch.cuda.empty_cache()
gc.collect()
```

**V√©rifier l'utilisation:**

```python
# Pendant l'entra√Ænement
print(f"M√©moire utilis√©e: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
print(f"M√©moire r√©serv√©e: {torch.cuda.memory_reserved() / 1e9:.2f} GB")
```

---

## üîß R√©solution de Probl√®mes

### Erreur: "Runtime disconnected"

**Causes:**
- Session inactive trop longtemps
- D√©passement du quota GPU
- Erreur dans le code

**Solutions:**
1. Runtime > Reconnect
2. R√©ex√©cuter les cellules depuis le d√©but
3. V√©rifier les logs pour erreurs

---

### Erreur: "Out of Memory (OOM)"

**Message:** `CUDA out of memory`

**Solutions:**

```python
# 1. R√©duire batch_size
per_device_train_batch_size = 1
gradient_accumulation_steps = 16

# 2. Utiliser gradient checkpointing
use_gradient_checkpointing = True

# 3. R√©duire max_seq_length
max_seq_length = 1024  # Au lieu de 2048

# 4. Activer quantification
load_in_4bit = True
```

---

### Erreur: "No GPU available"

**Cause:** Runtime CPU s√©lectionn√©

**Solution:**
1. Runtime > Change runtime type
2. Hardware accelerator > GPU
3. Save
4. Runtime > Restart runtime

---

### Erreur: "Cannot access HuggingFace model"

**Message:** `GatedRepoError` ou `401 Unauthorized`

**Solutions:**
1. Accepter les conditions: [Llama 3.2](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)
2. Cr√©er un token: [Settings > Tokens](https://huggingface.co/settings/tokens)
3. Authentifier:
   ```python
   from huggingface_hub import login
   login(token="your_token_here")
   ```

---

### Erreur: "Module not found"

**Cause:** D√©pendance manquante

**Solution:**

```python
# Installer la d√©pendance
!pip install -q package_name

# Ou r√©installer toutes les d√©pendances
!pip install -q -r /content/memoire/requirements.txt
```

---

## üí° Conseils et Bonnes Pratiques

### 1. Gestion des Sessions

‚úÖ **√Ä faire:**
- Sauvegarder r√©guli√®rement (Drive ou W&B)
- Utiliser des checkpoints
- Ex√©cuter cellule par cellule pour d√©boguer
- V√©rifier GPU avant entra√Ænement long

‚ùå **√Ä √©viter:**
- Laisser session inactive (timeout)
- Entra√Æner sans sauvegardes
- Ignorer les warnings de m√©moire
- Ex√©cuter plusieurs notebooks en parall√®le

---

### 2. Optimisation des Co√ªts

**Colab Pro ($9.99/mois):**
- Architecture 2 et 3 fonctionnent bien
- Architecture 1 possible mais plus lent

**Colab Pro+ ($49.99/mois):**
- Recommand√© pour Architecture 1 (fine-tuning)
- A100 GPU pour entra√Ænement rapide
- Sessions plus longues et stables

**Astuce:** Commencer avec Pro, passer √† Pro+ si n√©cessaire

---

### 3. Organisation du Travail

**Structure recommand√©e dans Drive:**
```
MyDrive/
‚îî‚îÄ‚îÄ memoire/
    ‚îú‚îÄ‚îÄ data/                # Donn√©es (copi√© une fois)
    ‚îú‚îÄ‚îÄ checkpoints/         # Checkpoints d'entra√Ænement
    ‚îú‚îÄ‚îÄ models/              # Mod√®les finaux
    ‚îú‚îÄ‚îÄ outputs/             # R√©sultats et logs
    ‚îî‚îÄ‚îÄ notebooks/           # Notebooks modifi√©s (optionnel)
```

---

### 4. Workflow Recommand√©

**Session Typique:**

1. **Pr√©paration (5 min)**
   - Ouvrir notebook
   - V√©rifier runtime (GPU, RAM)
   - Monter Drive si n√©cessaire
   - Cloner repository

2. **Ex√©cution (30 min - 4h)**
   - Ex√©cuter cellules de configuration
   - Lancer entra√Ænement/exp√©riences
   - Monitorer avec W&B

3. **Sauvegarde (5 min)**
   - Sauvegarder mod√®le dans Drive
   - Exporter m√©triques
   - T√©l√©charger r√©sultats importants

4. **Nettoyage**
   - Arr√™ter runtime si termin√©
   - Lib√©rer ressources pour autres utilisateurs

---

## üìä M√©triques de Performance Attendues

### Architecture 1 (Fine-tuning)

**Avec V100 (Colab Pro):**
- Temps par epoch: ~30-45 minutes
- Epochs recommand√©s: 3-5
- Dur√©e totale: 2-3 heures
- M√©moire GPU: ~12-14 GB

**Avec A100 (Colab Pro+):**
- Temps par epoch: ~15-20 minutes
- Dur√©e totale: 1-1.5 heures
- M√©moire GPU: ~12-14 GB

---

### Architecture 2 (RAG)

**Avec T4:**
- Indexation: ~5-10 minutes
- Requ√™te RAG: ~2-3 secondes
- M√©moire GPU: ~6-8 GB

---

### Architecture 3 (RAG-Agentique)

**Avec V100:**
- Configuration: ~10-15 minutes
- Cycle ReAct: ~3-5 secondes
- M√©moire GPU: ~8-10 GB

---

## üéì Ressources Suppl√©mentaires

### Documentation
- [Google Colab FAQ](https://research.google.com/colaboratory/faq.html)
- [Colab Pro Features](https://colab.research.google.com/signup)
- [HuggingFace Authentication](https://huggingface.co/docs/hub/security-tokens)
- [Weights & Biases Guide](https://docs.wandb.ai/guides)

### Communaut√©
- [GitHub Repository](https://github.com/AmedBah/memoire)
- [Issues](https://github.com/AmedBah/memoire/issues)
- Support EasyTransfert: 2522018730

---

## üìû Support

Pour toute question ou probl√®me:

1. V√©rifier ce guide
2. Consulter les [Issues GitHub](https://github.com/AmedBah/memoire/issues)
3. Cr√©er une nouvelle issue si n√©cessaire
4. Contacter: support@easytransfert.ci

---

**Bon entra√Ænement sur Colab Pro! üöÄ**

*Derni√®re mise √† jour: 2024-10-12*
